{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d87a1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, './result2_converted_2.txt')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try loading the .pkl file again and converting its content to a .txt file\n",
    "import pickle\n",
    "# Path to the newly uploaded .pkl file\n",
    "pkl_file_path_new = './result2.pkl'\n",
    "\n",
    "# Attempt to load the content of the new pickle file\n",
    "try:\n",
    "    with open(pkl_file_path_new, 'rb') as file:\n",
    "        data_new = pickle.load(file)\n",
    "        \n",
    "    # Assuming the data is successfully loaded and can be serialized to text\n",
    "    txt_content_new = str(data_new)\n",
    "    txt_file_path_new = pkl_file_path_new.replace('.pkl', '_converted_2.txt')\n",
    "    \n",
    "    # Write the content to a text file\n",
    "    with open(txt_file_path_new, 'w') as file:\n",
    "        file.write(txt_content_new)\n",
    "    \n",
    "    success_new = True\n",
    "except Exception as e:\n",
    "    success_new = False\n",
    "    error_message_new = str(e)\n",
    "    txt_file_path_new = \"\"\n",
    "\n",
    "(success_new, txt_file_path_new if success_new else error_message_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bafd82b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 3 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 파일 열기 및 JSON 데이터 로드\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 8\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 데이터 처리 예시: 첫 번째 데이터 항목의 'point_cloud' 정보 출력\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoint_cloud\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/pythonProject1/lib/python3.9/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pythonProject1/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/.conda/envs/pythonProject1/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/.conda/envs/pythonProject1/lib/python3.9/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 3 (char 2)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 파일 경로\n",
    "file_path = './val_converted_2.json'\n",
    "\n",
    "# 파일 열기 및 JSON 데이터 로드\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 데이터 처리 예시: 첫 번째 데이터 항목의 'point_cloud' 정보 출력\n",
    "print(data[0]['point_cloud'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "009e94c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749\n",
      "{'point_cloud': {'num_features': 4, 'lidar_idx': '006732'}, 'image': {'image_idx': '006732', 'image_shape': array([ 375, 1242], dtype=int32)}, 'calib': {'P2': array([[7.21537720e+02, 0.00000000e+00, 6.09559326e+02, 4.48572807e+01],\n",
      "       [0.00000000e+00, 7.21537720e+02, 1.72854004e+02, 2.16379106e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.74588400e-03],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]), 'R0_rect': array([[ 0.9999239 ,  0.00983776, -0.00744505,  0.        ],\n",
      "       [-0.0098698 ,  0.9999421 , -0.00427846,  0.        ],\n",
      "       [ 0.00740253,  0.00435161,  0.9999631 ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
      "      dtype=float32), 'Tr_velo_to_cam': array([[ 7.53374491e-03, -9.99971390e-01, -6.16602018e-04,\n",
      "        -4.06976603e-03],\n",
      "       [ 1.48024904e-02,  7.28073297e-04, -9.99890208e-01,\n",
      "        -7.63161778e-02],\n",
      "       [ 9.99862075e-01,  7.52379000e-03,  1.48075502e-02,\n",
      "        -2.71780610e-01],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         1.00000000e+00]])}, 'annos': {'name': array(['Car'], dtype='<U3'), 'truncated': array([0.]), 'occluded': array([0.]), 'alpha': array([1.77]), 'bbox': array([[377.18, 190.5 , 544.45, 310.79]], dtype=float32), 'dimensions': array([[3.88, 1.44, 1.67]]), 'location': array([[-2.1 ,  1.74, 10.98]], dtype=float32), 'rotation_y': array([1.59]), 'score': array([-1.]), 'difficulty': array([0], dtype=int32), 'index': array([0], dtype=int32), 'gt_boxes_lidar': array([[11.26999283,  2.11766267, -0.95515513,  3.88      ,  1.67      ,\n",
      "         1.44      , -3.16079633]]), 'num_points_in_gt': array([855], dtype=int32)}}\n",
      "\n",
      "\n",
      "[[377.18 190.5  544.45 310.79]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 파일 경로 지정\n",
    "file_path = './val.pkl'\n",
    "\n",
    "# pkl 파일 불러오기\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# 데이터 타입 및 첫 번째 항목 출력 (예시)\n",
    "print(len(data))\n",
    "# print(data[0])\n",
    "\n",
    "for idx, data_dict in enumerate(data):\n",
    "    print(data_dict)\n",
    "    print()\n",
    "    print()\n",
    "    print(data_dict['annos']['bbox'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b5b9cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/KITTI/images/train/000332.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '/workspace/KITTI/images/train/000332.png'\n",
    "a[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ed3df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./000015_all_bbox.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define 'DontCare' bounding boxes and draw them in blue\n",
    "dontcare_bboxes = [\n",
    "    (916.14, 175.59, 973.32, 253.55),\n",
    "    (628.80, 173.19, 653.95, 196.66),\n",
    "    (610.47, 175.76, 625.72, 205.87),\n",
    "    (766.54, 168.32, 841.38, 261.86),\n",
    "    (464.22, 177.67, 508.93, 230.69)\n",
    "]\n",
    "\n",
    "# Load the previously updated image\n",
    "image_with_bboxes = Image.open(updated_bbox_image_path)\n",
    "\n",
    "# Draw the 'DontCare' bounding boxes on the image in blue\n",
    "draw = ImageDraw.Draw(image_with_bboxes)\n",
    "for bbox in dontcare_bboxes:\n",
    "    draw.rectangle(bbox, outline=\"blue\", width=2)\n",
    "\n",
    "# Save the image with all bounding boxes\n",
    "all_bbox_image_path = './000015_all_bbox.png'\n",
    "image_with_bboxes.save(all_bbox_image_path)\n",
    "all_bbox_image_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7a21edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0부터 153까지의 숫자를 포맷에 맞추어 txt 파일에 작성하는 코드 예시입니다.\n",
    "\n",
    "file_path = \"./0019.txt\"  # 원하는 파일 경로로 변경하세요\n",
    "\n",
    "with open(file_path, \"w\") as file:\n",
    "    for number in range(1059):\n",
    "        # 숫자를 6자리 형식으로 포맷팅 (예: 000000, 000001, ...)\n",
    "        formatted_number = f\"{number:06d}\"\n",
    "        file.write(f\"{formatted_number}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fceb449",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './0000.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    content = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Now, `content` contains all lines from your text file without the newline characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "699eac22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P0: 7.215377000000e+02 0.000000000000e+00 6.095593000000e+02 0.000000000000e+00 0.000000000000e+00 7.215377000000e+02 1.728540000000e+02 0.000000000000e+00 0.000000000000e+00 0.000000000000e+00 1.000000000000e+00 0.000000000000e+00',\n",
       " 'P1: 7.215377000000e+02 0.000000000000e+00 6.095593000000e+02 -3.875744000000e+02 0.000000000000e+00 7.215377000000e+02 1.728540000000e+02 0.000000000000e+00 0.000000000000e+00 0.000000000000e+00 1.000000000000e+00 0.000000000000e+00',\n",
       " 'P2: 7.215377000000e+02 0.000000000000e+00 6.095593000000e+02 4.485728000000e+01 0.000000000000e+00 7.215377000000e+02 1.728540000000e+02 2.163791000000e-01 0.000000000000e+00 0.000000000000e+00 1.000000000000e+00 2.745884000000e-03',\n",
       " 'P3: 7.215377000000e+02 0.000000000000e+00 6.095593000000e+02 -3.395242000000e+02 0.000000000000e+00 7.215377000000e+02 1.728540000000e+02 2.199936000000e+00 0.000000000000e+00 0.000000000000e+00 1.000000000000e+00 2.729905000000e-03',\n",
       " 'R_rect 9.999239000000e-01 9.837760000000e-03 -7.445048000000e-03 -9.869795000000e-03 9.999421000000e-01 -4.278459000000e-03 7.402527000000e-03 4.351614000000e-03 9.999631000000e-01',\n",
       " 'Tr_velo_cam 7.533745000000e-03 -9.999714000000e-01 -6.166020000000e-04 -4.069766000000e-03 1.480249000000e-02 7.280733000000e-04 -9.998902000000e-01 -7.631618000000e-02 9.998621000000e-01 7.523790000000e-03 1.480755000000e-02 -2.717806000000e-01',\n",
       " 'Tr_imu_velo 9.999976000000e-01 7.553071000000e-04 -2.035826000000e-03 -8.086759000000e-01 -7.854027000000e-04 9.998898000000e-01 -1.482298000000e-02 3.195559000000e-01 2.024406000000e-03 1.482454000000e-02 9.998881000000e-01 -7.997231000000e-01']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e46669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 이미지에 대해 예측과 실제 레이블을 저장하는 구조를 만듭니다.\n",
    "predictions_per_image = defaultdict(lambda: defaultdict(list))  # {image_id: {class_id: [predictions]}}\n",
    "ground_truths_per_image = defaultdict(lambda: defaultdict(list))  # {image_id: {class_id: [ground_truths]}}\n",
    "\n",
    "# 이미지별로 예측 및 실제 레이블을 수집합니다.\n",
    "for image_id in range(num_images):\n",
    "    for pred in predict(model, image_id):\n",
    "        predictions_per_image[image_id][pred['class_id']].append(pred)\n",
    "    for gt in get_ground_truths(image_id):\n",
    "        ground_truths_per_image[image_id][gt['class_id']].append(gt)\n",
    "\n",
    "# 각 이미지에 대한 매칭과 성능 지표 계산을 수행합니다.\n",
    "tps = defaultdict(list)\n",
    "fps = defaultdict(list)\n",
    "fns = defaultdict(list)\n",
    "\n",
    "for image_id in predictions_per_image:\n",
    "    for class_id in predictions_per_image[image_id]:\n",
    "        preds = predictions_per_image[image_id][class_id]\n",
    "        gts = ground_truths_per_image[image_id].get(class_id, [])\n",
    "        \n",
    "        # 이 함수 내에서 각 이미지에 대한 TP, FP, FN을 계산합니다.\n",
    "        tp, fp, fn = calculate_tp_fp_fn(preds, gts, iou_threshold=0.5)\n",
    "        \n",
    "        # 각 클래스별로 TP, FP, FN을 저장합니다.\n",
    "        tps[class_id].append(tp)\n",
    "        fps[class_id].append(fp)\n",
    "        fns[class_id].append(fn)\n",
    "\n",
    "# 각 클래스별로 Precision과 Recall 계산\n",
    "precisions = {}\n",
    "recalls = {}\n",
    "aps = []\n",
    "\n",
    "for class_id in tps:\n",
    "    # 각 클래스별로 TP, FP, FN을 집계합니다.\n",
    "    tp_sum = np.sum(tps[class_id])\n",
    "    fp_sum = np.sum(fps[class_id])\n",
    "    fn_sum = np.sum(fns[class_id])\n",
    "    \n",
    "    # Precision과 Recall을 계산합니다.\n",
    "    precision = tp_sum / (tp_sum + fp_sum) if (tp_sum + fp_sum) > 0 else 0\n",
    "    recall = tp_sum / (tp_sum + fn_sum) if (tp_sum + fn_sum) > 0 else 0\n",
    "    \n",
    "    # 이를 저장합니다.\n",
    "    precisions[class_id] = precision\n",
    "    recalls[class_id] = recall\n",
    "    \n",
    "    # 클래스별 AP 계산\n",
    "    ap = tp_sum / (tp_sum + fp_sum + fn_sum) if (tp_sum + fp_sum + fn_sum) > 0 else 0\n",
    "    aps.append(ap)\n",
    "    print(f\"AP for class {class_id}: {ap}\")\n",
    "\n",
    "# mAP 계산\n",
    "mAP = np.mean(aps)\n",
    "print(f\"mAP: {mAP}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e5fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114505f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 예측 및 실제 레이블을 이미지 ID와 함께 저장\n",
    "predictions = defaultdict(lambda: defaultdict(list))  # {image_id: {class_id: [confidence scores]}}\n",
    "ground_truths = defaultdict(lambda: defaultdict(list))  # {image_id: {class_id: [ground truth boxes]}}\n",
    "\n",
    "# 가정: 이미지별 predictions, ground_truths는 이미 준비되어 있음\n",
    "for image_id in range(total_images):\n",
    "    for pred in predictions[image_id]:\n",
    "        predictions[image_id][pred['class_id']].append(pred['confidence'])\n",
    "    for gt in ground_truths[image_id]:\n",
    "        ground_truths[image_id][gt['class_id']].append(gt)\n",
    "\n",
    "# 클래스별 AP 및 전체 mAP 계산\n",
    "aps = defaultdict(list)  # {class_id: [AP scores per image]}\n",
    "for image_id in range(total_images):\n",
    "    for class_id in sorted(all_detections.keys()):\n",
    "        if class_id in predictions[image_id] and class_id in ground_truths[image_id]:\n",
    "            # 계산된 confusion matrix로부터 TP, FP, FN을 추출\n",
    "            cm = confusion_matrix(\n",
    "                ground_truths[image_id][class_id], \n",
    "                predictions[image_id][class_id], \n",
    "                labels=[0, 1]  # 가정: 클래스 레이블은 0과 1\n",
    "            )\n",
    "            TP = cm[1, 1]\n",
    "            FP = cm[0, 1]\n",
    "            FN = cm[1, 0]\n",
    "\n",
    "            # Precision과 Recall 계산\n",
    "            precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "            recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "\n",
    "            # Precision과 Recall로 AP 계산\n",
    "            aps[class_id].append(average_precision_score([precision], [recall]))\n",
    "\n",
    "# 모든 이미지에 대해 각 클래스별 AP를 평균하여 최종 mAP 계산\n",
    "final_mAP = {class_id: np.mean(aps[class_id]) for class_id in aps}\n",
    "print(f\"mAP per class: {final_mAP}\")\n",
    "print(f\"Final mAP: {np.mean(list(final_mAP.values()))}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
